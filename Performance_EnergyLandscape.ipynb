{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance_EnergyLandscape.ipynb\n",
    "\n",
    "### Imports and Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the functions we created\n",
    "from Functions import (\n",
    "    run_experiment,    # for generating data \n",
    "    load_and_merge_data,\n",
    "    calculate_performance, \n",
    "    calculate_fail_rate,\n",
    "    plot_performance_and_rt,\n",
    "    compute_non_regret_performance,\n",
    "    plot_non_regret,\n",
    "    full_analysis_pipeline,\n",
    "    plot_energy_landscapes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_E': 60,\n",
    "    'n_I': 50,\n",
    "    'n_NSE': 280,\n",
    "    'gamma_ee': 1.2,\n",
    "    'gamma_ei': 0.0,\n",
    "    'gamma_ie': 0.0,\n",
    "    'gamma_ii': 0.0,\n",
    "    'top_down': False,\n",
    "    'n_Ctr': 500,\n",
    "    'S': 0.3,\n",
    "    'R': 1.0\n",
    "}\n",
    "coherence_index = 0  # [0, 3.2, 6.4, 12.8, 25.6, 51.2]\n",
    "coherence_list = [0, 3.2, 6.4, 12.8, 25.6, 51.2] # in percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=866.3\n",
      "Trial 2/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=919.3\n",
      "Trial 3/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=944.1\n",
      "Trial 4/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 5/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=850.1\n",
      "Trial 6/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=718.8\n",
      "Trial 7/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=947.7\n",
      "Trial 8/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=841.4\n",
      "Trial 9/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=836.2\n",
      "Trial 10/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=860.3\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh0_trialCount10_trialN0.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=0,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=955.3\n",
      "Trial 2/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=880.2\n",
      "Trial 3/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=879.0\n",
      "Trial 4/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=1011.5\n",
      "Trial 5/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=894.8\n",
      "Trial 6/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 7/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=880.8\n",
      "Trial 8/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=775.9\n",
      "Trial 9/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=930.8\n",
      "Trial 10/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=870.8\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh0_trialCount10_trialN2.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=0,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=770.1\n",
      "Trial 2/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=852.0\n",
      "Trial 3/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=885.0\n",
      "Trial 4/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 5/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=908.6\n",
      "Trial 6/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=848.2\n",
      "Trial 7/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=896.8\n",
      "Trial 8/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=737.6\n",
      "Trial 9/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=792.4\n",
      "Trial 10/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh0_trialCount10_trialN3.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=0,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=947.5\n",
      "Trial 2/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=920.5\n",
      "Trial 3/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=807.3\n",
      "Trial 4/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 5/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 6/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=877.3\n",
      "Trial 7/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=879.4\n",
      "Trial 8/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=906.2\n",
      "Trial 9/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=839.9\n",
      "Trial 10/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=793.7\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh0_trialCount10_trialN4.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=0,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=933.2\n",
      "Trial 2/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=801.3\n",
      "Trial 3/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=788.9\n",
      "Trial 4/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 5/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=942.9\n",
      "Trial 6/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=843.1\n",
      "Trial 7/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=937.7\n",
      "Trial 8/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=1011.7\n",
      "Trial 9/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=982.1\n",
      "Trial 10/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=992.0\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh3.2_trialCount10_trialN2.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=1,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=1044.6\n",
      "Trial 2/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=905.2\n",
      "Trial 3/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=989.8\n",
      "Trial 4/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=1010.6\n",
      "Trial 5/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=903.5\n",
      "Trial 6/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=873.7\n",
      "Trial 7/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 8/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 9/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=907.8\n",
      "Trial 10/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh3.2_trialCount10_trialN3.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=1,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=899.2\n",
      "Trial 2/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=805.7\n",
      "Trial 3/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=794.4\n",
      "Trial 4/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=840.5\n",
      "Trial 5/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=812.2\n",
      "Trial 6/10: EL_firing=0, ER_firing=1, NO_decision=0, Trial_RT=849.7\n",
      "Trial 7/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 8/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=903.8\n",
      "Trial 9/10: EL_firing=0, ER_firing=0, NO_decision=1, Trial_RT=None\n",
      "Trial 10/10: EL_firing=1, ER_firing=0, NO_decision=0, Trial_RT=801.7\n",
      "Saved Result_list to data/EE1.2_EI0.0_IE0.0_II0.0_coh3.2_trialCount10_trialN4.pkl\n"
     ]
    }
   ],
   "source": [
    "Result_list, total_EL_RT, total_ER_RT, NO_decision, EL_firing, ER_firing = run_experiment(\n",
    "    params=params,\n",
    "    coherence_list=coherence_list,\n",
    "    coherence_index=1,\n",
    "    num_trial=10,\n",
    "    threshold=60,\n",
    "    trial_len=2000,\n",
    "    BG_len=300,\n",
    "    input_amp=0.00156,\n",
    "    trial_n='4'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Load and Merge Data from Multiple Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Suppose you have multiple .pkl files for different coherence or repeated runs.\n",
    "# For example, let's imagine you generated them with different 'trial_n' or num_trial.\n",
    "# We'll just show how you'd merge them if you had a list of file paths.\n",
    "\n",
    "# Example list of file paths (replace with real files you have)\n",
    "file_paths_example = [\n",
    "    \"EE1.2_EI0.0_IE0.0_II0.0_0_trialCount10_trialN0.pkl\",\n",
    "    # Add more if you've done multiple runs...\n",
    "]\n",
    "\n",
    "# Merge them (shifting keys by step=100 for each file)\n",
    "merged_data, final_offset = load_and_merge_data(file_paths_example, initial_offset=0, step=100)\n",
    "print(\"Merged Data size:\", len(merged_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Performance / RT / Fail Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute performance for the merged_data example:\n",
    "performance, avg_er_rt, std_er_rt = calculate_performance(merged_data)\n",
    "fail_rate = calculate_fail_rate(merged_data)\n",
    "\n",
    "print(\"Performance (fraction of E_R decisions):\", performance)\n",
    "print(\"Avg E_R Reaction Time:\", avg_er_rt)\n",
    "print(\"Std E_R Reaction Time:\", std_er_rt)\n",
    "print(\"Fail Rate:\", fail_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot a Psychometric Curve for Multiple Conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to compare multiple parameter sets (e.g., Pol0 vs. Pol2), \n",
    "# you'd produce or load data for each set of gamma or 'pol' parameter, \n",
    "# store the performance in a dict keyed by e.g. \"coh0\", \"coh3.2\", etc.\n",
    "# Then call 'plot_performance_and_rt'.\n",
    "\n",
    "# For demonstration, let's assume we have two dicts: results_pol0, results_pol2\n",
    "# Each is keyed like: \"coh0\" -> {\"Performance\": p, \"Avg_ER_Reaction_Time\": r, \"Std_ER_Reaction_Time\": s}, etc.\n",
    "\n",
    "# We'll do a quick fake example:\n",
    "\n",
    "coherence_list_for_plot = [0, 3.2, 6.4, 12.8, 25.6, 51.2]\n",
    "\n",
    "results_pol0 = {\n",
    "    \"coh0\":   {\"Performance\": 0.5, \"Avg_ER_Reaction_Time\": 350, \"Std_ER_Reaction_Time\": 40},\n",
    "    \"coh3.2\": {\"Performance\": 0.6, \"Avg_ER_Reaction_Time\": 330, \"Std_ER_Reaction_Time\": 35},\n",
    "    \"coh6.4\": {\"Performance\": 0.7, \"Avg_ER_Reaction_Time\": 320, \"Std_ER_Reaction_Time\": 30},\n",
    "    \"coh12.8\":{\"Performance\": 0.75,\"Avg_ER_Reaction_Time\": 310, \"Std_ER_Reaction_Time\": 25},\n",
    "    \"coh25.6\":{\"Performance\": 0.8, \"Avg_ER_Reaction_Time\": 300, \"Std_ER_Reaction_Time\": 20},\n",
    "    \"coh51.2\":{\"Performance\": 0.9, \"Avg_ER_Reaction_Time\": 290, \"Std_ER_Reaction_Time\": 15},\n",
    "}\n",
    "\n",
    "results_pol2 = {\n",
    "    \"coh0\":   {\"Performance\": 0.52, \"Avg_ER_Reaction_Time\": 360, \"Std_ER_Reaction_Time\": 42},\n",
    "    \"coh3.2\": {\"Performance\": 0.63, \"Avg_ER_Reaction_Time\": 345, \"Std_ER_Reaction_Time\": 38},\n",
    "    \"coh6.4\": {\"Performance\": 0.71, \"Avg_ER_Reaction_Time\": 325, \"Std_ER_Reaction_Time\": 32},\n",
    "    \"coh12.8\":{\"Performance\": 0.77,\"Avg_ER_Reaction_Time\": 315, \"Std_ER_Reaction_Time\": 28},\n",
    "    \"coh25.6\":{\"Performance\": 0.82, \"Avg_ER_Reaction_Time\": 305, \"Std_ER_Reaction_Time\": 22},\n",
    "    \"coh51.2\":{\"Performance\": 0.88, \"Avg_ER_Reaction_Time\": 295, \"Std_ER_Reaction_Time\": 18},\n",
    "}\n",
    "\n",
    "plot_performance_and_rt(\n",
    "    coherence_list_for_plot,\n",
    "    results_polA=results_pol0,\n",
    "    results_polB=results_pol2,\n",
    "    labelA=\"Pol0\",\n",
    "    labelB=\"Pol2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute and Plot Non-Regret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can compute non-regret from a given 'Result_list' or merged dict\n",
    "bm = np.arange(0, 12, 0.6)  # example benchmark array\n",
    "\n",
    "nr_data_example = compute_non_regret_performance(merged_data, bm)\n",
    "print(\"Non-Regret data shape:\", len(nr_data_example))\n",
    "\n",
    "# Suppose you have multiple 'pol' conditions; you'd store them in a dictionary \n",
    "# and then plot with 'plot_non_regret'.\n",
    "NR_results_dict = {\n",
    "    \"Pol0\": nr_data_example,   # this is a single example\n",
    "    # \"Pol2\": other array,\n",
    "    # ...\n",
    "}\n",
    "labels_dict = {\"Pol0\": \"Pol0, GammaEE=0.2\"} # or whatever label you want\n",
    "\n",
    "plot_non_regret(bm, NR_results_dict, labels_dict, title=\"Non-Regret Example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using the Full Analysis Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a dictionary of file paths grouped by coherence values,\n",
    "# you can use 'full_analysis_pipeline' to load everything, compute performance, \n",
    "# and do non-regret automatically.\n",
    "\n",
    "file_paths_dict = {\n",
    "    0:   [\"GammaEE0.2_GammaEI0.0_GammaIE0.0_GammaII0.0_coh0_trialCount10_trialNTest.pkl\"],\n",
    "    3.2: [\"GammaEE0.2_GammaEI0.0_GammaIE0.0_GammaII0.0_coh3.2_trialCount10_trialNTest.pkl\"],\n",
    "    # etc...\n",
    "}\n",
    "benchmark_array = np.arange(0, 12, 0.6)\n",
    "\n",
    "all_merged_results, perf_dict, non_regret_dict = full_analysis_pipeline(file_paths_dict, benchmark_array)\n",
    "\n",
    "print(\"Performance dict:\\n\", perf_dict)\n",
    "print(\"Non-Regret dict:\\n\", non_regret_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot Energy Landscapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can plot the energy landscape for a particular 'Result_list' \n",
    "# (or merged_data) using 'plot_energy_landscapes'.\n",
    "\n",
    "# 'time_window' is a list of (start_ms, end_ms) relative to reaction start time.\n",
    "time_windows = [\n",
    "    (0, 50),     # from 0 ms to 50 ms after reaction start\n",
    "    (50, 100),   # from 50 ms to 100 ms\n",
    "]\n",
    "\n",
    "# For demonstration, let's assume we want excitatory difference (EXC=True) \n",
    "# and a limit of 40. We'll also plot full scale.\n",
    "\n",
    "plot_energy_landscapes(\n",
    "    Result_list,       # or merged_data\n",
    "    time_window=time_windows,\n",
    "    plot_full_scale=True,\n",
    "    EXC=True,\n",
    "    lim=40\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
